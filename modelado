#--------------------------------------------------------------------------------
# SCRIPT COMPLETO PARA MODELADO DE PREDICCIÓN DE FUGA (CHURN)
#--------------------------------------------------------------------------------

# Paso 0: Instalación y Carga de Librerías
# (Ejecuta estas líneas una vez si no tienes los paquetes)
# install.packages(c("readxl", "dplyr", "caTools", "caret", "pROC", "rpart", "rpart.plot", "randomForest", "xgboost", "Matrix"))

library(readxl)
library(dplyr)
library(caTools)       # Para dividir los datos (train/test)
library(caret)         # Para preprocesamiento y evaluación (matriz de confusión)
library(pROC)          # Para la curva ROC y el AUC
library(rpart)         # Para Árboles de Decisión
library(rpart.plot)    # Para graficar Árboles de Decisión
library(randomForest)  # Para el modelo Random Forest
library(xgboost)       # Para el modelo XGBoost
library(Matrix)        # Requerido por XGBoost



set.seed(42)
split <- sample.split(df_modelar$CHURN, SplitRatio = 0.8)
train_data <- subset(df_modelar, split == TRUE)
test_data <- subset(df_modelar, split == FALSE)


# --- PASO CLAVE ADICIONAL (Alternativa si no se agrupan categorías) ---
# Si no usas la estrategia de `fct_lump_n`, necesitarías este paso para unificar.
# 1. Obtener todos los niveles de los factores del dataset completo
# levels_marca <- levels(df_modelar$MARCA)
# levels_depto <- levels(df_modelar$DEPARTAMENTO_MOV)
#
# 2. Aplicar estos niveles a los conjuntos de entrenamiento y prueba
# train_data$MARCA <- factor(train_data$MARCA, levels = levels_marca)
# test_data$MARCA <- factor(test_data$MARCA, levels = levels_marca)
# train_data$DEPARTAMENTO_MOV <- factor(train_data$DEPARTAMENTO_MOV, levels = levels_depto)
# test_data$DEPARTAMENTO_MOV <- factor(test_data$DEPARTAMENTO_MOV, levels = levels_depto)
# --- Fin del paso clave ---


cat("### Verificación de Niveles del Factor 'MARCA' ###\n")
cat("Niveles en Train:", length(levels(train_data$MARCA)), "\n")
cat("Niveles en Test:", length(levels(test_data$MARCA)), "\n")
# Ahora ambos números deberían ser idénticos.

#-------------------------------------------------------------------------------
# Paso 1: Cargar y Preparar los Datos para el Modelo
#-------------------------------------------------------------------------------

df_raw <- read_excel("modelo_completo.xlsx")

df_modelar <- df_raw %>%
  mutate(
    Prima_Ultimo_Periodo = as.numeric(gsub("[\\$\\,\\s]", "", `Prima_Ultimo_Periodo`)),
    CHURN = as.factor(make.names(CHURN)), # Nombres válidos: X0, X1
    NCL = as.numeric(NCL),
    GENDER = as.factor(GENDER),
    DEPARTAMENTO_MOV = as.factor(DEPARTAMENTO_MOV),
    MARCA = as.factor(MARCA)
  ) %>%
  # Seleccionar solo las variables predictoras y la variable objetivo
  select(
    CHURN, Antiguedad_dias, NCL, Prima_Ultimo_Periodo, Variacion_Pct_Prima_Ultima_Renovacion,
    VEHAGE, DEPARTAMENTO_MOV, MARCA, AGE, GENDER,
    Consultas_Cotizaciones_Propias, Consultas_Cotizaciones_Otras
  ) %>%
  # Eliminar filas con valores NA para simplificar este ejemplo
  na.omit()

#-------------------------------------------------------------------------------
# Paso 2: Dividir los Datos en Entrenamiento (80%) y Prueba (20%)
#-------------------------------------------------------------------------------
set.seed(42) # Para que la división sea reproducible
split <- sample.split(df_modelar$CHURN, SplitRatio = 0.8)
train_data <- subset(df_modelar, split == TRUE)
test_data <- subset(df_modelar, split == FALSE)

cat("### Tamaño de los Conjuntos de Datos ###\n")
cat("Entrenamiento:", nrow(train_data), "filas\n")
cat("Prueba:", nrow(test_data), "filas\n")

#-------------------------------------------------------------------------------
# Paso 3: Modelo 1 - REGRESIÓN LOGÍSTICA
#-------------------------------------------------------------------------------
cat("\n### Construyendo Modelo 1: Regresión Logística ###\n")

# Entrenar el modelo
# La fórmula CHURN ~ . significa "predecir CHURN usando todas las demás variables"
log_model <- glm(CHURN ~ ., data = train_data, family = "binomial")

# Revisar los coeficientes y su significancia
# Un Pr(>|z|) bajo (ej. < 0.05) indica que la variable es un predictor significativo.
summary(log_model)

# Realizar predicciones en el conjunto de prueba
prob_log <- predict(log_model, newdata = test_data, type = "response")
pred_log <- ifelse(prob_log > 0.5, "X1", "X0") # Convertir probabilidad a clase

# Evaluar el modelo
cat("\n--- Matriz de Confusión: Regresión Logística ---\n")
conf_matrix_log <- confusionMatrix(as.factor(pred_log), test_data$CHURN)
print(conf_matrix_log)

#-------------------------------------------------------------------------------
# Paso 4: Modelo 2 - RANDOM FOREST
#-------------------------------------------------------------------------------
cat("\n### Construyendo Modelo 2: Random Forest ###\n")
# (Primero, un árbol de decisión simple para visualización)
tree_model <- rpart(CHURN ~ ., data = train_data, method = "class")
rpart.plot(tree_model, extra = 101, box.palette = "Blues", main="Árbol de Decisión Simple")


# Ahora, el modelo Random Forest completo
# ntree: número de árboles a construir. mtry: número de variables a probar en cada división.
rf_model <- randomForest(CHURN ~ ., data = train_data, ntree = 500, mtry = 4, importance = TRUE)

# Realizar predicciones
pred_rf <- predict(rf_model, newdata = test_data)

# Evaluar el modelo
cat("\n--- Matriz de Confusión: Random Forest ---\n")
conf_matrix_rf <- confusionMatrix(pred_rf, test_data$CHURN)
print(conf_matrix_rf)

# Ver la importancia de las variables
cat("\n--- Importancia de Variables: Random Forest ---\n")
varImpPlot(rf_model, main="Importancia de Variables (Random Forest)")


#-------------------------------------------------------------------------------
# Paso 5: Modelo 3 - GRADIENT BOOSTING (XGBoost)
#-------------------------------------------------------------------------------
cat("\n### Construyendo Modelo 3: XGBoost ###\n")

# XGBoost requiere un formato de datos específico: una matriz numérica
# Convertimos los datos de entrenamiento
train_matrix <- sparse.model.matrix(CHURN ~ . -1, data = train_data)
train_label <- as.numeric(as.character(recode(train_data$CHURN, X0 = 0, X1 = 1)))
dtrain <- xgb.DMatrix(data = train_matrix, label = train_label)

# Convertimos los datos de prueba
test_matrix <- sparse.model.matrix(CHURN ~ . -1, data = test_data)
test_label <- as.numeric(as.character(recode(test_data$CHURN, X0 = 0, X1 = 1)))
dtest <- xgb.DMatrix(data = test_matrix, label = test_label)

# Entrenar el modelo
xgb_model <- xgboost(
  data = dtrain,
  nrounds = 100,
  objective = "binary:logistic", # Para clasificación binaria
  eta = 0.1,
  max_depth = 4,
  verbose = 0 # No mostrar mensajes durante el entrenamiento
)

# Realizar predicciones
prob_xgb <- predict(xgb_model, newdata = dtest)
pred_xgb <- ifelse(prob_xgb > 0.5, "X1", "X0")

# Evaluar el modelo
cat("\n--- Matriz de Confusión: XGBoost ---\n")
conf_matrix_xgb <- confusionMatrix(as.factor(pred_xgb), test_data$CHURN)
print(conf_matrix_xgb)

# Ver la importancia de las variables
cat("\n--- Importancia de Variables: XGBoost ---\n")
xgb_imp <- xgb.importance(model = xgb_model)
xgb.plot.importance(importance_matrix = xgb_imp, main="Importancia de Variables (XGBoost)")

#-------------------------------------------------------------------------------
# Paso 6: Comparación de Modelos y Conclusiones
#-------------------------------------------------------------------------------
cat("\n\n### TABLA COMPARATIVA DE RENDIMIENTO DE MODELOS ###\n\n")

# Extraer las métricas clave de cada matriz de confusión
stats_log <- conf_matrix_log$byClass
stats_rf <- conf_matrix_rf$byClass
stats_xgb <- conf_matrix_xgb$byClass

# Calcular AUC para cada modelo
auc_log <- roc(test_data$CHURN, prob_log)$auc
auc_rf <- roc(test_data$CHURN, as.numeric(predict(rf_model, newdata=test_data, type="prob")[,2]))$auc
auc_xgb <- roc(test_label, prob_xgb)$auc

# Crear la tabla comparativa
comparacion <- data.frame(
  Modelo = c("Regresión Logística", "Random Forest", "XGBoost"),
  Accuracy = c(conf_matrix_log$overall['Accuracy'], conf_matrix_rf$overall['Accuracy'], conf_matrix_xgb$overall['Accuracy']),
  Sensitivity_Recall = c(stats_log['Sensitivity'], stats_rf['Sensitivity'], stats_xgb['Sensitivity']), # Qué tan bien predice los que SÍ se van
  Specificity = c(stats_log['Specificity'], stats_rf['Specificity'], stats_xgb['Specificity']), # Qué tan bien predice los que se quedan
  Precision = c(stats_log['Precision'], stats_rf['Precision'], stats_xgb['Precision']), # De los que predijo que se iban, cuántos acertó
  AUC = c(auc_log, auc_rf, auc_xgb)
)

print(comparacion)
